/*
 * Muse FFT brainwave visualiser
 * Written in Processing 2.2.1
 * by Sarah Bennett (sarahb@cse.unsw.edu.au)
 * 2014-10-01
 *
 * How to run:
 * 1) Run muse-io, with the dsp output set, specifying a UDP port
 * eg: ./muse-io --device 00:06:66:69:4F:8B --50hz --dsp --osc "osc.udp://localhost:5000"
 * where --device is your Muse's mac address
 *
 * 2) Run this script with Processing
 *
 * 3) Enjoy :)
 */
  
// Import the required packages for OSC interfacing
import oscP5.*;
import netP5.*;
  
/*
FEATURES TO ADD:
  
* live EEG data (in another tab?)
* logging to file
* scrolling the screen, not going over the page
*/
  
  
// set up the OSC stuff
OscP5 oscP5;
NetAddress myRemoteLocation;
  
color bgColor = color(0);
PFont font;
PFont bigFont;
  
// Number of data channels
//int numChannels = 4;
int numChannels = 1;
  
// Some globals: current X position where we're drawing data; width of the lines we're drawing
int currentPosition = 0;
int drawWidth = 1; //Speed of the drawing, the higher the faster
float strokeSize = 3.0; //10 = pas pire
  
// The names of the waves, in any order
//String waves[] = {
//  "alpha_relative", "beta_relative", "gamma_relative", "delta_relative", "theta_relative"
//};
String waves[] = {
  "alpha_relative", "beta_relative", "gamma_relative"
};
int numBuckets = waves.length;
boolean isFinished = false;
boolean printed = false;
String userName;
  
// Store the current data as it comes in. lastPos contains the n-1th data point, and values contains the nth.
float lastPos[][] = new float[numBuckets][numChannels];
float values[][] = new float[numBuckets][numChannels];

PGraphics screenshot;
PGraphics screenshotFonce;

ArrayList<Particle> particles;
float lifespan = 50.0;

// Set up the program
void setup() {
  font = createFont("OratorStd.otf", 32);
  bigFont = createFont("OratorStd.otf", 96);
  
  particles = new ArrayList<Particle>();
  
  // Specify the screen size
  //size(1920, 1080);
  fullScreen();
  // Set up the OSC stuff
  oscP5 = new OscP5(this, 5000);
  //myRemoteLocation = new NetAddress("127.0.0.1", 5000);
  
  // Set the background color of the screen
  background(bgColor);
  strokeWeight(strokeSize);
  
  background(bgColor);
  
  userName = generateUser();
  
  screenshot = createGraphics(1080, 1080);
  screenshotFonce = createGraphics(1920, 1080); //THIS IS THE ONE TO SEND TO THE RASPI
  
  //screenshot.background(bgColor);
  //screenshotFonce.background(bgColor);
  initScreenshots();
  // Specify that we're in HSB color mode
  //colorMode(HSB);
}
  
// This function gets called every time any OSC message comes in.
// Within the function, we can check if a given message matches the one we're after, and react accordingly.
// This is in contrast to other OSC interfaces, which set up handlers for each type of message that can come in.
// I'm not sure whether this is possible to do in Processing with the current libraries.
void oscEvent(OscMessage theOscMessage) {
  
  // For each type of wave [alpha, beta, ...]
  for (int curWave = 0; curWave < waves.length; curWave++) {
    // If the wave matches the DSP data for that wave
    if (theOscMessage.checkAddrPattern("/muse/elements/" + waves[curWave]) == true) {
      // Make sure that we have the type tag right: ffff means four floats, which is what we'll get when the Muse is set to preset 10.
      if (theOscMessage.checkTypetag("ffff")) {
        // For each of the channels of data (4, in preset 10)
        for (int i=0; i<numChannels; i++) {
          // Store the current data point in the array
          values[curWave][i] = theOscMessage.get(i).floatValue();
          //println(theOscMessage.get(i).floatValue());
        }
      }
    }
  }
  if(theOscMessage.checkAddrPattern("/Stimulix/push1") == true) {
    if(theOscMessage.get(0).floatValue() == 1)
      restartEEG();
  }
}
  
// This is where we actually draw the graphics onto the screen
// This function takes the data from the global array, and draws each of the data points on the screen,
// wrapping around as the screen gets filled.
// Each wave is drawn in a different color, and it also displays the names of the waves with their current values [scaled from 0-1 to 0-100], for each channel.
void draw() {
  screenshot.beginDraw();
  screenshotFonce.beginDraw();
  
  //screenshot.background(255);
  screenshot.stroke(0);
  screenshotFonce.stroke(0);
  // Set the fill color to black, and turn off strokes
  fill(bgColor);
  noStroke();
  
  //clear();
  // Draw a rectangle to cover the background in black, before overwriting the wave data
  rect(currentPosition, 0, drawWidth*5+width, height);
  rect(0, height - 200, width, height);
  fill(color(0, 0, 0));
  textFont(font);
  text(userName, width - 150, height - 75);
  textFont(bigFont);
  screenshot.fill(0);
  screenshot.strokeWeight(4);
  screenshot.text(userName, 1080 - 150, height - 75);
  screenshotFonce.fill(0);
  screenshotFonce.strokeWeight(16);
  screenshotFonce.textFont(bigFont);
  screenshotFonce.pushMatrix();
  //translate(width / 2 - 90, height - 75);
  screenshotFonce.translate(100, height - 15);
  screenshotFonce.rotate(-HALF_PI);
  screenshotFonce.text(userName, 0, 0);
  screenshotFonce.popMatrix();
  
  
  // The top and bottom position of where we're going to draw
  float top, bottom;
  
  if(!isFinished) {
    // For each channel:
    for (int curChannel = 0; curChannel < numChannels; curChannel++) {
       
      // Specify the boundaries of where we're drawing
      //top = map(curChannel, 0, numChannels, height, 30);
      //bottom = map(curChannel+1, 0, numChannels, height, 30);
      top = map(curChannel, 0, numChannels, height, 30);
      bottom = map(curChannel+1, 0, numChannels, height, 30);
      
      // Draw a rectangle to clear where the text about each waveform is going to be
      fill(bgColor);
      noStroke();
      rect(0, bottom-30, width, 30);
    
      // For each of the buckets / wave types:
      for (int i=0; i<numBuckets; i++) {
        //println(curChannel);
        // Specify the color for this wavetype
        int c = color(255/7.0*i, 255, 255);
        //println(i);
        
        if(i == 0) {
          c = color(255, 255, 0);
        }
        if(i == 1) {
          c = color(255, 0, 255); 
        }
        if(i == 2) {
          c = color(0, 255, 255); 
        }
         
        // Create the text, talking about the waveform with its values
        fill(c);
        //textAlign(TOP, LEFT);
        //text(waves[i] + "(" + str(int(values[i][curChannel]*100)) + ")", 15+i*100, bottom-15);
         
        // Draw the line of the waveform
        stroke(c);
        line(currentPosition, map(lastPos[i][curChannel], 0, 1, top-30, bottom) - height / 3, currentPosition+drawWidth, map(values[i][curChannel], 0, 1, top-30, bottom) - height / 3);
        addParticle(width / 2, height / 2);
        screenshot.line(currentPosition, map(lastPos[i][curChannel], 0, 1, top-30, bottom) - 300, currentPosition+drawWidth, map(values[i][curChannel], 0, 1, top-30, bottom) - 300);
        screenshotFonce.line(currentPosition, map(lastPos[i][curChannel], 0, 1, top-30, bottom) - height / 3, currentPosition+drawWidth, map(values[i][curChannel], 0, 1, top-30, bottom) - height / 3);
        //println(currentPosition);
        
        // Update where we came from, for drawing the next line
        lastPos[i][curChannel] = values[i][curChannel];
      }
    }
  }
  screenshot.endDraw();
  screenshotFonce.endDraw();
  // Update the current x position across the page, and wrap around when we hit the end
  currentPosition+=drawWidth;
  if(currentPosition >= width) {
    isFinished = true;
  }
  if(isFinished && !printed) {
    printed = true;
    printEEG();
  }
  for (int i = particles.size()-1; i >= 0; i--) {
    Particle p = particles.get(i);
    p.run();
    if (p.isDead()) {
      particles.remove(i);
    }
  }
  //currentPosition %= width;
  
}

void addParticle(int x, int y) {
  particles.add(new Particle(new PVector(x, y), new PVector(0,0.2), lifespan));
}

void initScreenshots() {
  screenshot.beginDraw();
  screenshotFonce.beginDraw();
  screenshot.background(bgColor);
  screenshotFonce.background(bgColor);
}

String generateUser() {
  //return "" + year() + month() + day() + hour() + minute() + second();
  //return "" + String.format("%02d", hour()) + minute() + second();
  return "" + String.format("%02d", hour()) + String.format("%02d", minute()) + String.format("%02d", second());
}

void restartEEG() {
  //if(isFinished)
  //  printEEG();
  userName = generateUser();
  background(bgColor);
  initScreenshots();
  //screenshot.background(bgColor);
  //screenshot.clear();
  //screenshotFonce.background(bgColor);
  //screenshotFonce.clear();
  //fill(bgColor);
  println("restart");
  resetValues();
  isFinished = false;
  printed = false;
  currentPosition = 0;
}

void printEEG() {
  println("PRINT ME");
  //filter(GRAY); 
  //filter(THRESHOLD, 0.9);
  //saveFrame("C:/Users/Hugo/Dropbox/Screenshots/eeg/eeg-" + userName + ".png");
  
  //screenshot.save("C:/Users/Hugo/Dropbox/Screenshots/eeg/eeg-pgraphics-" + userName + ".png");
  //screenshotFonce.save("C:/Users/Hugo/Dropbox/Screenshots/eeg/eeg-pgraphics-" + userName + ".png");
  //screenshot.save("Z:/Python-Thermal-Printer/gfx/print.png");
  screenshotFonce.save("C:/Users/Hugo/Dropbox/Screenshots/eeg/eeg-raspi" + userName + ".png");
  saveFrame("C:/Users/Hugo/Dropbox/Screenshots/eeg/eeg-" + userName + ".png");
  //screenshotFonce.save("Z:/Python-Thermal-Printer/gfx/print.png");
  //saveFrame("Z:/Python-Thermal-Printer/gfx/print.png");
  screenshotFonce.save("Z:/Python-Thermal-Printer/gfx/print.png");
  screenshot.background(bgColor);
  screenshot.clear();
  screenshotFonce.background(bgColor);
  screenshotFonce.clear();
}

void resetValues() {
  //values = null;
  values = new float[numBuckets][numChannels];
}

void keyPressed() {
  if (key == ' ') {
    restartEEG();
  }
}